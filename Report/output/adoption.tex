\section{Exploration of differences in adoption estimates on DSW villages}

This Section compares adoption estimates calculated using different methodologies and discusses potential reasons for the differences between them. This exploratory analysis is descriptive in nature and intended to assess the plausibility of different hypotheses for explaining the observed differences. It relies on subsamples of our data sets so we can compare like to like, but these subsamples are sometimes limited in size. While this approach helps discount some hypotheses, it cannot conclusively identify the causes behind the differences in estimates.

Evidence Action’s Q3 Monitoring estimates are roughly twice as high as our main estimates (Table \ref{tab:compare-adoption}). Section \ref{sec:adoption-ea} discusses several hypotheses that may explain this difference, though we lack sufficient data to test them adequately. Our Household Survey estimates represent 52\% and 58\% of Q3 Monitoring estimates in Malawi and Uganda, respectively—proportions consistent with Kenya’s SCM findings, where independent surveyors obtained chlorination rates representing 55\% of those calculated by Evidence Action. A combination of sampling variation and surveyor incentives most likely explains these differences.

In Malawi, or main estimates of chlorine adoption among households using water points with DSW included in  26.6\% (95\% CI = 21.1-32.1)\footnote{Table \ref{tab:headlines-vil}, column 7.} are not statistically from those obtained through the Monitoring methods 26.6\% (95\% CI = 21.1-32.1)\footnote{Table \ref{tab:headlines-am}}. This suggests that \textbf{although several factors may bias estimates obtained under the Monitoring methodology, a full census of served villages may not be necessary to obtain reliable adoption estimates}. In Uganda, however, the estimates from the same two surveys differ significantly. Section \ref{sec:adoption-dil} discusses potential explanations for this difference. A combination of sample selection, survey timing, and interactions with promoters is likely biasing Monitoring estimates upward in Uganda. 

\subsection{Potential explanations for differences between this report's and Evidence Action's estimates}

\subsubsection{Surveyor's independence}

A key methodological difference between DIL and Evidence Action protocols is who collects the data. DIL’s estimates rely on data collected by independent enumerators hired by IPA, while Evidence Action uses their own local staff. This means surveyors and promoters may respond to different incentives:

\begin{itemize}
    \item Evidence Action surveyors may have existing relationships with promoters or implementation teams, creating incentives to portray them positively;
    \item Promoters were chosen by their communities to be the point of contact with Evidence Action and may seek to maintain positive relationships with the organization;
    \item Evidence Action staff may have interests in program continuation, which depends on positive results.
\end{itemize}

All these factors create potential incentives for surveyors and promoters to seek outcomes favorable to program success, which we would expect to bias Evidence Action estimates upward relative to those obtained via independent surveys.

Although we lack the data to test the impact of this factor on estimates, empirical evidence from Kenya supports the hypothesis that it does play a role. When Evidence Action examined identical households using both measurement approaches, the independent household survey found that 21\% of households tested positive for chlorine residual, while the Evidence Action monitoring survey reported 38\%. This means the independent survey estimate represented only 55\% of the Evidence Action figure.

Are results are consistent with the findings from Kenya (Table 1). In Malawi, the independent household survey estimate (26.6\%) represents 52\% of the Evidence Action monitoring figure (51\%). Similarly, in Uganda, the independent estimate (30.1\%) represents 58\% of the Evidence Action monitoring result (52\%).

\subsubsection{Sample selection of of water points}

The water points included in Evidence Action’s Adoption Monitoring Survey and our Promoter Survey are systematically different due to contrasting treatment of water points whose promoter could not be surveyed.

Our protocol specified that only promoters (and ILC operators in ILC villages) should be surveyed and asked to provide a list of water point users. When Evidence Action did not provide contact information for a promoter or one could not be identified by asking villagers, no user list was obtained and no households were sampled from that list to respond to the Household Survey. Evidence Action, by contrast, surveys any knowledgeable village member when the promoter cannot be found.

This difference in sampling strategy has implications for the representativeness of our data and may bias estimates. However, the expected direction of bias works against explaining the observed gap:

\begin{itemize}
    \item Evidence Action’s broader respondent pool likely produces more representative estimates of overall program reach.
    \item Our promoter-focused approach would be expected to introduce upward bias into estimates following the monitoring method, as promoters are better positioned than typical village members to identify both households using the water points and households that chlorinate their water, and may be more motivated to prioritize successfully adopting households when selecting survey respondents. The promoters who can be more easily identified are also more likely to be in touch with Evidence Action and, presumably, to be conducting promotion activities in the village, which should lead to higher chlorine adoption rates.
\end{itemize}

Given that our Monitoring estimates are lower than Evidence Action’s Q3 Monitoring estimates, and that in Malawi—where coverage is more representative—Monitoring Survey estimates are closer to Household Survey estimates, the difference in water point representativeness is unlikely to explain the overall divergence in estimates.

\subsubsection{Survey timing and duration}

Both ours and Evidence Action protocols stipulate that promoters should only be contacted when the surveyor is ready ready to conduct the interview. However, the survey activities differed substantially in duration: Evidence Action monitoring staff spent only one day in each village, while IPA teams remained for an average of five days, conducting monitoring surveys on the final day.

The extended presence of IPA field teams may bias chlorine adoption estimates in both the Household and Monitoring Surveys upward, as promoters have opportunities to refill dispensers and remind households to add chlorine to their drinking water.

Our estimates point in the opposite direction: among households that completed the Household Survey, those tested on the first day showed higher rates of TCR detection in both Malawi and Uganda. However, there is limited statistical support for this finding -- the difference is significant only in Uganda, at 10\% significance level. 

\subsubsection{Other possible causes of divergence}

The following factors may contribute to the differences, but we are unable to test them adequately:

\begin{itemize}
    \item \textbf{Water point sampling variation:} IPA and Evidence Action did not visit the same water points, and sampling variation may explain part of the difference.
    \item \textbf{Time since training of surveyors:} IPA surveyors were trained between one week and four months before interviews took place, but the timing of Evidence Action staff retraining is unknown. This would introduce noise into measurements, though the direction of any bias is unclear.
    \item \textbf{State of equipment:} The equipment used in our data collection was procured specifically for this exercise, and all reagents were new. We lack data about how long Evidence Action’s equipment has been in use or when reagents were procured. The use of old materials could bias estimates in either direction -- for example, discolored color wheels would bias estimates upward, while degraded DPD reagents would bias estimates downward.
    \item \textbf{Deviations from randomization protocol:} Household randomization into our Household Survey was recorded in the data, allowing us to observe whether sampled households were replaced. In Evidence Action’s protocol, this is recorded on paper, leaving more room for enumerators to choose whom they survey (e.g., households closer to the promoter’s house or households indicated by the promoter).

\end{itemize}

\section{Potential explanations for differences between Tables \ref{tab:headlines-vil} and \ref{tab:headlines-am}}

This section discusses potential explanations for the differences shown in Figure 2. Figure 3 presents TCR detection rates across different subsamples of households tested during the Household Survey in an attempt to decompose the sources of differences.
As expected given the similarity between Monitoring and Household Survey estimates in Malawi, there is no meaningful variation in chlorine residual detection rates across subsamples in that country. In Uganda, the estimates in Figure 2 are significantly different (p-value = 0.053) and point estimates in Household Survey subsamples become more similar to Monitoring Survey estimates as we apply similar sample selection criteria. However, there is considerable noise in estimates across the subsamples in Figure 3, and they are not significantly different from one another. As such, the discussion in this Section remains inconclusive.

2.1 Sample selection of water points
When designing survey protocols, we intended for both the Household Survey and Monitoring Survey to be representative of all DSW water points in sampled villages. However, as discussed in Section 1.2, the field team was unable to identify promoters for all water points found, meaning water points covered by the Monitoring Survey may be systematically different from and less representative than those in the Household Survey.
Tables 2 and 3 compare characteristics of water points for which promoters were surveyed versus those for which no promoter was found in Malawi and Uganda, respectively. Promoter surveys were conducted in 84.6% of the 136 water points with DSW identified in Malawi, and in 62.7% of the 185 water points in Uganda. In both countries, an F-test for joint orthogonality indicates that water points excluded from the promoter survey are not significantly different from those covered. However, there are imbalances in individual characteristics, particularly those linked to dispenser functionality.
These differences in water point characteristics could translate into Monitoring Survey households having greater access to chlorine than Household Survey households. Indeed, Figure 4 shows that TCR detection rates are significantly higher among households using water points covered by the promoter survey.
Although this difference is large and significant, in Malawi, the weight of these households in Household Survey estimates is small (only 6.9% of households in the Household Survey sample use water points not included in the promoter survey) and the differences between Household and Monitoring estimates are correspondingly small.
In Uganda, by contrast, only 20.5% of households in the Household Survey sample use water points included in the promoter survey. This is also visible in the reduction in sample size between columns (1) and (2) in Figure 3. Nonetheless, restricting the Household Survey sample to households using water points included in the promoter survey does not substantially increase the TCR detection rate.
2.2 Sample selection of households
The list of households using water points provided by promoters is another potential source of difference. Promoters are expected to have less complete knowledge than households about water point usage patterns, and they also respond to incentives.
Promoters’ reduced knowledge would introduce noise into the data. For example, in some cases promoters relied on lists of water point users recorded in previous years, dating back as far as dispenser installation. Several additional factors could bias estimates in different directions:
If a household uses more than one water point, promoters may not know whether a water point is the household’s primary drinking water source, and including households whose primary source lacks DSW would bias estimates downward
If promoters wish to demonstrate that a water point is widely used and should continue being treated, the list could include households whose primary source lacks DSW
If promoters remember mostly people with whom they have closer relationships or to whom they recently discussed chlorination, the list could lead to overestimation of chlorination rates
If promoters expect surveyors to speak with listed households and wish to demonstrate good performance, the list will more likely include households known to use chlorine, biasing estimates upward Promoters would be expected to list all households using the water point regardless of location, while the household survey limits its sample to households within or up to 200m outside village boundaries
The data shows that promoters are effective at identifying households using water points with dispensers. In Malawi, out of the 4,975 households included in the promoter list who were identified in the household census, 70.8% self-report using a water point with a dispenser as their primary source of drinking water. In Uganda, this figure was 77.3% out of 4,022 households.
However, promoters are less effective at identifying all of the users. Among the households mapped in the household census who self-reported using water points in the promoter survey as their primary source of drinking water, 78.8% are included in the promoter list in Malawi, while in Uganda the figure is just 52%.
Among households that self-report using water points listed by the promoter, those included in thethe promoter list are significantly different from those that are not (Tables 4 and 5), including with regard to chlorine access. However, when we further restrict the sample to households included in the Household Survey, these differences are not jointly significant. This finding is consistent with results in Figures 3 and 5. Figure 3 shows that restricting the Household Survey sample to households included in the promoter list does not lead to different adoption estimates, and Figure 5 confirms this by showing that TCR detection is similar among households included in and excluded from the list.
Although this does not point to differences between the Household Survey and Monitoring Survey estimates, the fact that differences exist between listed and not listed households observed in the Household Census indicates that inclusion in the promoter list does play a role and may help explain divergences from Evidence Action estimates.
2.3 Interactions with the promoter
The analysis thus far suggests that eligibility criteria for inclusion in the Monitoring Survey are not the primary source of differences. However, we know from Figure 1 that differences exist in Uganda. Therefore, these differences must stem not from eligibility but from something observed among households actually included in the survey.
In Figure 3 we observe that households randomized into the survey show higher detection rates than those who were not randomly sampled. While this is a small sample and the difference is not statistically different from previous estimates, a comparison of listed households that were and were not randomly sampled reveals an interesting pattern.
When comparing household characteristics, we find that more sampled than non-sampled households reported being aware of the upcoming data collection and that it was the promoter who informed them. The same is observed when comparing households included in the Monitoring Survey to those included in the Household Survey. In both cases, households are not significantly different overall, making these findings inconclusive. However, Figure 6 shows that households interacting with the promoter are more likely to chlorinate.
This may not explain why Household Survey estimates differ from Q3 Monitoring, but it does shed light on the gap between Household Survey and Monitoring Survey estimates. In Malawi, where no anecdotal evidence points to the same involvement among promoters, these estimates are not different.
2.4 Other factors
Replacement protocol: During the Household Survey, households were only replaced after three failed attempts at a visit. For the Monitoring Survey, the protocol indicated that households could be replaced for two reasons:
They had already been surveyed during the Household Survey
They were unavailable when visited for the Monitoring Survey. This could lead to bias if households where a member is more likely to be found at home during the data are also more likely to chlorinate or to have collected water more recently.
Figure 7 compares chlorine detection rates among households sampled for the Monitoring Survey and replaced because they had already been surveyed in the Household Survey versus replacement households in the Monitoring Survey. These differences are not statistically significant, but they are relatively large in Uganda. In Malawi, most replacements occurred because households had already been surveyed in the Household Survey, while in Uganda, approximately 40% of replacements occurred because households were unavailable.
Timing: Because Monitoring Surveys were the last activity carried out in each village, taking place after promoters were surveyed, there is greater potential for priming (upward bias). The ideal test to determine if timing biases estimates would compare the same households surveyed in both the Household and Monitoring Surveys. However, given our protocol, too few such observations exist for meaningful analysis. Some evidence for the presence of timing effects appears in Figure 2. Note, however, that timing could not explain the difference between our estimates and Evidence Action’s, given that the Evidence Action Monitoring protocol involves only one day of presence in the village.
Village boundaries: The Household Census from which the Household Survey sample was selected included only people living inside village boundaries or within 200m of these boundaries, while the Promoter Survey included anyone using the water points regardless of location. This does not appear to contribute to the observed differences, as households living outside village boundaries show lower chlorination rates in the Household Survey (Figure 8), and the difference between Household and Monitoring Survey estimates persists when restricting comparison to households within village boundaries (Figure 9). These households represent a higher proportion of the Household Survey sample than the Monitoring Survey sample. Therefore, if anything, this would bias estimates in the opposite direction to what we observe.
