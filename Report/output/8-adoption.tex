\section{\label{sec:adoption}Exploration of differences in adoption estimates}

This Section compares adoption estimates calculated using different methodologies and discusses potential reasons for the differences between them. This analysis is descriptive in nature and intended to assess the plausibility of different hypotheses for explaining the observed differences. It relies on subsamples of our data sets to restrict them to comparable observations, but these subsamples are often small. While this approach allows us to rule out some hypotheses, it cannot conclusively identify the causes behind the differences in estimates, and point estimates should not be taken at face value.

Evidence Action’s Q3 Monitoring estimates of take-up among DSW users are roughly twice as high as our main estimates (Table \ref{tab:compare-adoption}). Section \ref{sec:adoption-ea} discusses several hypotheses that may explain this difference, though we lack sufficient data to test them adequately. Our Household Survey estimates represent 53\% and 58\% of Q3 Monitoring estimates in Malawi and Uganda, respectively — proportions consistent with Kenya’s SCM findings, where independent surveyors obtained chlorination rates representing 55\% of those calculated by Evidence Action. \textbf{We discard priming and sample selection of water points in our main estimate as potential explanations for these differences, pointing to a combination of sampling variation, surveyor incentives, and potential deviations from survey protocols as more likely causes.}

Our main theory was sample selection, but we don't see this. What we see is that households in Uganda are more likely to have been warned by promoters. We see a slightly higher chlorination rate among households in the promoter list, but the difference is not statistcally significate and the AM happens in the same day, so there is nothing in our data to suggest that there should be systematic differences. Likely aproblem with the anumerators measurement or follow of protocol.

\textcolor{red}{In Malawi, our main estimates of chlorine adoption among households using water points with DSW are not statistically different from those obtained through the Adoption Monitoring methods \textcolor{red}{FIGURE}. This suggests that \textbf{although several factors may bias estimates obtained under the Monitoring methodology, a full census of served villages may not be necessary to obtain adoption estimates}. In Uganda, however, the estimates from the same two surveys differ significantly (p-value = 0.0005), from a main estimate of 30.4\% (95\% CI = 24.8-36.1)\footnote{Table \ref{tab:headlines-vil}, column 7.} and to a Monitoring estimate of 43.4\% (95\% CI = 35.9-50.9)\footnote{Table \ref{tab:headlines-am}}. Section \ref{sec:adoption-dil} discusses potential explanations for this difference. \textbf{A combination of sampling variation, \textcolor{red}{sample selection} and priming is likely biasing Monitoring estimates upward in Uganda.}} However, this is unlikely to affect Evidence Action's measures. 

Although we find evidence that promoter reports of households use is very noisy, we find that this does not affect chlorination rates.

\subsection{Potential explanations for differences between this report's and Evidence Action's estimates}\label{sec:adoption-ea} 

\subsubsection{Surveyor's independence}

A key methodological difference between DIL and Evidence Action protocols is who collects the data. Our estimates rely on data collected by independent enumerators hired by IPA, while Evidence Action uses their own local staff. This means surveyors and promoters may respond to different incentives:

\begin{itemize}
    \item Evidence Action surveyors may have existing relationships with promoters or implementation teams, creating incentives to portray them positively;
    \item Promoters were chosen by their communities to be the point of contact with Evidence Action and may seek to maintain positive relationships with the organization;
    \item Evidence Action staff may have interests in program continuation, which depends on positive results.
\end{itemize}

All these factors create potential incentives for surveyors and promoters to seek outcomes favorable to program success, which we would expect to bias Evidence Action estimates upward relative to those obtained via independent surveys.

Although we lack the data to test the impact of this factor on estimates, empirical evidence from Kenya supports the hypothesis that it does play a role. When Evidence Action examined identical households using both measurement approaches, the independent household survey found that 21\% of households tested positive for chlorine residual, while the Evidence Action Monitoring Survey reported 38\%. This means the independent survey estimate represented only 55\% of the Evidence Action figure.

Our results are consistent with the findings from Kenya (Table \ref{tab:compare-adoption}). In Malawi, the independent household survey estimate (26\%) represents 51\% of the Evidence Action monitoring figure (51\%). Similarly, in Uganda, the independent estimate (30\%) represents 58\% of the Evidence Action monitoring result (52\%).\footnote{Table \ref{tab:compare-adoption}.}

\subsubsection{Sample selection of water points}

The water points included in Evidence Action’s Adoption Monitoring Survey and our Promoter Survey are systematically different due to contrasting treatment of water points whose promoter could not be surveyed.

Our protocol specified that only promoters should be surveyed and asked to provide a list of water point users, unless the field team managed to identify the person responsible for refilling the dispenser/ILC device or the ILC operator. When Evidence Action did not provide contact information for a promoter or one could not be identified by asking villagers, no user list was obtained and no households were sampled from that list to respond to the Household Survey. Evidence Action, by contrast, surveys any knowledgeable village member when the promoter cannot be found.

This difference in sampling strategy has implications for the representativeness of our data and may bias estimates. However, the expected direction of bias works against explaining the observed gap:

\begin{itemize}
    \item Evidence Action’s broader respondent pool likely produces more representative estimates of overall program reach.
    \item Our promoter-focused approach would be expected to introduce upward bias into estimates following the monitoring method, as promoters are better positioned than typical village members to identify both households using the water points and households that chlorinate their water, and may be more motivated to prioritize successfully adopting households when selecting survey respondents. The promoters who can be more easily identified are also more likely to be in touch with Evidence Action and, presumably, to be conducting promotion activities in the village, which should lead to higher chlorine adoption rates.
\end{itemize}

Given that our Monitoring estimates are lower than Evidence Action’s Q3 Monitoring estimates, and that in Malawi — where coverage of water points by the Promoter Survey is higher — Monitoring Survey estimates are closer to Household Survey estimates, the difference in water point representativeness is unlikely to explain the overall divergence in estimates.

\subsubsection{Survey timing and duration}\label{sec:adoption-priming}

Both ours and Evidence Action's protocols stipulate that promoters should only be contacted when the surveyor is ready to conduct the interview. However, the survey activities differed substantially in duration: Evidence Action monitoring staff spent only one day in each village, while IPA teams remained for an average of five days, conducting Monitoring Surveys on the final day.

\textit{The extended presence of IPA field teams may bias chlorine adoption estimates in both the Household and Monitoring Surveys upward}, as promoters have opportunities to refill dispensers and remind households to add chlorine to their drinking water and the village population becomes more aware of water treatment practices. Note, however, that this finding should \textit{decrease} the difference between Evidence Action's estimates and ours. \textit{Therefore, it does not help us explain the observed results. }

\subsubsection{Other possible causes of divergence}

The following factors may contribute to the differences, but we are unable to test them adequately:

\begin{itemize}
    \item \textbf{Water point sampling variation:} IPA and Evidence Action did not sample the same water points, and sampling variation may explain part of the difference.
    \item \textbf{Time since training of surveyors:} IPA surveyors were trained between one week and four months before interviews took place, but the timing of Evidence Action staff retraining is unknown. This would introduce noise into measurements, but the direction of any bias is unclear, as more experience may lead surveyors to develop better skills and judgement or to forget protocols and develop bad practices.
    \item \textbf{State of equipment:} The equipment used in our data collection was procured specifically for this exercise, and all reagents were new. We lack data about how long Evidence Action’s equipment has been in use or when reagents were procured. The use of old materials could bias estimates in either direction -- for example, discolored color wheels would bias estimates upward, while degraded DPD reagents would bias estimates downward.
    \item \textbf{Deviations from randomization protocol:} Household randomization into our Household Survey was recorded in the data, allowing us to observe whether sampled households were replaced. In Evidence Action’s protocol, this is recorded on paper, leaving more room for enumerators to choose whom they survey (e.g., households closer to the promoter’s house or households indicated by the promoter).

\end{itemize}

\subsection{Potential explanations for differences estimates obtained using the Census and the Adoption Monitoring methods}\label{sec:adoption-dil}

This section discusses potential explanations for the differences in chlorine residual detection rates observed between our main estimates, shown in Table \ref{tab:headlines-vil}, and estimates that approximate Evidence Action's Adoption Monitoring protocols, shown in Table \ref{tab:headlines-am}.

Figure \ref{fig:adoption-comparison} compares the TCR detection rates across the different methods used. In Uganda, the DSW estimates from the Adoption Monitoring method are significantly different (p-value = 0.053) from our main estimates. 
In Malawi, DSW estimates are similar across the two methods, but different for ILC. 


and point estimates in Household Survey subsamples become more similar to Monitoring Survey estimates as we apply similar sample selection criteria. However, there is considerable noise in estimates across the subsamples in \textcolor{red}{Figure \ref{fig:chlorine-vil}}, and they are not significantly different from one another. As such, the discussion in this Section remains inconclusive.

\textcolor{red}{Multiple potential sources of bias exist, and this analysis is merely observational. We observe sample selection into the promoter list using census-level data, even if not reflected in the Household Survey after randomization. Therefore, we cannot rule it out as a potential source of differences between the Household Survey and the Adoption Monitoring estimates. We also only observe differences between Monitoring and Household Survey estimates in Uganda — precisely where we know interference occurred — suggesting this as a potential cause of differences in estimates given the lack of support to other explanations. Enumerator identity (reflecting differences in bias, training, and equipment) is also likely to play a role.}

We lack definitive evidence from this data alone to conclude that obtaining lists from promoters should be avoided. However, given that Monitoring Survey estimates in both Kenya and Uganda were higher than Household Survey estimates, there is some evidence pointing in that direction.

\subsubsection{Sample selection of water points}

When designing survey protocols, we intended for estimates following both the census and the monitoring methods to be representative of all water points with in sampled villages. However, as discussed in Section \ref{sec:data}, the field team was unable to identify promoters for all water points found, meaning \textit{water points covered included in Adoption Monitoring estimates are systematically different from and less representative than those in the Census estimates.}

We find evidence of sample selection of water points into the Promoter Survey (Table \ref{tab:adoption-wp}). In Uganda, households using the water points with DSW covered by the Promoter Survey are around 90\% ($\simeq$ 36.3\%/23.9\%) more likely to have TCR detected in their water samples. In Malawi, there is no statistically significant difference among households using water points with DSW. However, households using water points with ILC covered by the Promoter Survey are roughly 50\% ($\simeq$ 33.8\%/18.1\%) more likely to have TCR detected. 

There are fewer households using water points excluded than included in the promoter survey in the Census Sample, so although sample selection is present, the difference in chlorine detected rates between all households in the Census Sample and those using water points covered by the Promoter Survey is not statistically significant (Figure \ref{fig:adoption-selection}, column 1 vs column 2). Therefore,\textbf{ sample selection of water points can only explain a small portion of the differences between our main estimates and those obtained when approximating Adoption Monitoring methods.}

\subsubsection{Sample selection of households}

The list of households using water points provided by promoters is another potential source of difference. Promoters’ more limited knowledge would introduce noise into the data. For example, in some cases promoters relied on lists of water point users recorded in previous years, dating back as far as dispenser installation. Several additional factors could bias estimates in different directions:

\begin{itemize}
    \item If a household uses more than one water point, promoters may not know whether a water point is the household’s primary drinking water source, and including households whose primary source lacks does not have DSW/ILC would bias estimates downward;
    \item If promoters wish to demonstrate that a water point is widely used and should continue being treated, the list could include households whose primary source lacks DSW;
    \item If promoters remember mostly people with whom they have closer relationships or to whom they recently discussed chlorination, the list could lead to overestimation of chlorination rates;
    \item If promoters expect surveyors to speak with listed households and wish to demonstrate good performance, the list will more likely include households known to use chlorine, biasing estimates upward;
    \item Promoters would be expected to list all households using the water point regardless of location, while the household survey limits its sample to households within or up to 200m outside village boundaries.
\end{itemize}

\textit{The data shows that promoters are relatively effective at identifying households using water points with dispensers}. Among the households in the Household Census matched to the list of users provided by promoters, between 73\% and 93\% confirmed to use water points with DSW/ILC as their primary source of drinking water (Table \ref{tab:adoption-matched}).


\textit{However, we also find evidence indicating that promoters are less effective at identifying \textbf{all} of the users, leaving part of the households reached out of their lists.} Among the households in the Household Census whose primary source of drinking water had DSW/ILC and was covered by the Promoter Survey, around 70\% are included in the promoter list in Malawi, while in Uganda this share is only 45\% (Table \ref{tab:adoption-hhs}). Therefore, there could be sample selection with regard to which households are included in the promoter lists.

\textit{Promoter lists also include households that use water points with DSW/ILC, but not as their primary source of drinking water.} Among households who has their drinking wate tested as part of the Promoter Sample, 85\% of those listed as using water points with DSW confirmed using them as their primary water sources (Table \ref{tab:adoption-hhs}). Among households listed as using water points with ILC, 78\% did. 

Since the combination of these factors could bias estimates in either direction, we compare the TCR detection rates among households in the Census Sample based on whether they were matched to the promoter list or not. The difference between the two groups is only significantly different in households using water points with ILC water point, and households \textit{not} included in the promoter list have higher TCR detection rates (Table \ref{tab:adoption-hhselection}).

These findings, combined with the lack of statistical significance in the TCR detection rates across the subsamples considered in Figure \ref{fig:adoption-comparison}, point to sample selection of households not playing a considerable role in the difference across estimates observed. Comparing columns (3) and (4) for Uganda in this figure further illustrates that sampling variation alone can lead to estimates similar to those observed in the Promoter Sample.



\subsubsection{Priming}

As discussed in Section \ref{sec:adoption-priming}, the duration of activities in the village could lead to an overestimation or adoption, as the time elapsed between the exposure to survey activities and the measurement of Chlorine Residual is long enough to change promoters' and users' practices. Because surveying Promoter Sample was the last activity carried out in each village, taking place after the Promoter Survey, the potential for bias is exacerbated in these estimates compared to the Census Sample.

To determine whether chlorine treatment practices change over the days when the field teams were in a village, we compare households in the Census Sample that were interviewed during the first day of Household Survey activities to those surveyed later on.\footnote{The ideal test to determine how households react to the presence of the survey team would compare Chlorine Residual detection rates in households surveyed as part of both the Census and the Promoter samples and determine whether they were higher in the second test. However, too few households in our data were tested twice. } In Uganda, households surveyed \textit{after} the first day are 30\% ($\simeq$ 37\%/28.1\%) more likely to have TCR detected in their water samples (Table \ref{tab:adoption-day}). The difference between the days is not significant in Malawi.

In Uganda, we observed cases where, following the water point census, the promoter visited households in the village and reminded them to treat their water with chlorine. After this, we included two questions in the survey: one asking whether they had discussed water treatment with the promoter in the week before the survey, and one asking if anyone had told them about the surveys happening in the village. Because these questions were only included when the data collection was almost complete, estimates are very noisy. We observe the following stylized facts:
\begin{itemize}
    \item Households who had discussed the data collection with someone in the village were more likely to test positive for TCR both in the Census (Figure \ref{fig:adoption-promoter}, columns (1) and (2)) and the Promoter Sample (Figure \ref{fig:adoption-promotermon}, columns (1) and (2));
    \item Households who had discussed the data collection with the promoter were even more likely to do so (Figures \ref{fig:adoption-promoter} and \ref{fig:adoption-promotermon}, columns (2) and (3));
    \item Households in Uganda were more likely than households in Malawi to have discussed the survey with someone and to have discussed water treatment with the promoter in the week before they were surveyed (Table \ref{tab:adoption-priming});
    \item Households in the promoter list were more likely to have discussed the survey and to have engaged with the promoter in the week before the survey than other households in the Census Sample, and households in the Promoter Sample are more likely to have done both than households in the Census Sample (Table \ref{tab:adoption-priming}).
\end{itemize}

\textit{As a result, we believe priming to be the most likely explanation for the higher chlorination rates observed in the Adoption Monitoring estimates in Uganda. }

\textbf{Therefore, although priming is the most likely reason for the differences observed between our Census and Promoter samples, it is unlikely to explain the differences observation between our main estimates and Evidence Action's Monitoring estimates.}

\subsubsection{Other possible explanations}

\begin{itemize}
    \item \textbf{Village boundaries:} As discussed in \ref{tab:diff-reach-outside}, while the Household Census restricts listed households to those living within 200m from the village boundaries, the Promoter Survey included anyone using the water points regardless of their location. However, we do not see this reflected in the shares of households outside the village in the data: around 7\% of the households in the Household Census that were also in a promoter list live outside of the village boundaries, compared to roughly 10\% among households not listed by a promoter. In the Household Survey, Chlorine detection rates are lower among households living outside of village boundaries \textcolor{red}{(Figure \ref{fig:adoption-boundaries})}, and there are more such households in the census sample (17\% of surveyed households) than in the monitoring sample (7\%), which could lower census estimates and explain part of the difference in estimates observed. However, there is still a 12 percentage point difference between census and Monitoring estimates in Uganda when restricting the comparison to households within village boundaries (p-value = 0.001).
    \item \textbf{Replacement protocol:} During the Household Survey, households were only replaced after three failed attempts at a visit. For the Monitoring Survey, the protocol indicated that households could be replaced for two reasons:
    \begin{enumerate}
        \item They had already been surveyed during the Household Survey; or
        \item They were unavailable when visited for the Monitoring Survey. This could lead to bias if households where a member is more likely to be found at home during the data are also more likely to chlorinate or to have collected water more recently.
    \end{enumerate}
    \textcolor{red}{Figure \ref{} compares chlorine detection rates among households sampled for the Monitoring Survey and replaced because they had already been surveyed in the Household Survey versus replacement households in the Monitoring Survey. These differences are not statistically significant, but they are relatively large in Uganda. In Malawi, most replacements occurred because households had already been surveyed in the Household Survey, while in Uganda, approximately 40\% of replacements occurred because households were unavailable.}
\end{itemize}