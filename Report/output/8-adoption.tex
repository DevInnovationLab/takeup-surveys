\section{\label{sec:adoption}Exploration of differences in adoption estimates}

This Section compares different adoption estimates and discusses potential reasons for the differences between them. The discussion is descriptive in nature, and intended to assess the plausibility of different explanations for the observed differences. It relies on subsamples of our data sets to restrict them to comparable observations, but these subsamples are often small. While this approach allows us to rule out some potential explanations, it cannot conclusively identify the causes behind the differences in estimates, and point estimates should not be taken at face value.

As discussed in Section \ref{sec:methods}, we conducted Chlorine Residual tests with two samples of households: the Census Sample, of households who self-report using water points with DSW/ILC, and the Promoter Sample, of households listed by promoters as using water points with DSW/ILC. Figure \ref{fig:adoption-comparison} compares three adoption estimates: the first two use data from the Census Sample, and the third uses date from the Promoter Sample. 

Section \ref{sec:adoption-dil} discusses the differences between these estimates. We find indications that priming, and interactions with promoters in particular, leads the Promoter Sample to overestimate adoption in Uganda. Sampling variation and sample selection of water points into the Promoter Survey likely reinforce this bias. In Malawi ILC villages, households in the Promoter Sample are less likely than households in the Census Sample to rely primarily on water points with ILC for their drinking water, and also less likely to have collected the tested water from those water points. We believe these to be the most important contributors to the lower Chlorine Residual detection rate in this sample.

Our objective in obtaining estimates from these two samples was to shed light on the differences between our main estimates and Evidence Action’s Q3 Monitoring results. Section \ref{sec:adoption-ea} discusses how our findings can be extended to explain what may be causing Evidence Action's DSW adoption estimates to be 73\% to 96\% higher than our main estimates in Uganda and Malawi, respectively. 

Although we lack sufficient data to adequately test all potential explanations for these differences, we find that
\begin{itemize}
    \item Sample selection of households is unlikely to lead to overestimation of chlorination rates, even if it cannot be entirely ruled out;
    \item The sample selection of water points observed in our Promoter Sample is not expected to affect Evidence Action's Adoption Monitoring estimates;
    \item Priming due to the survey duration is less likely to occur in Evidence Action's data collection than in ours;
    \item The proportions between our adoption estimates and Q3 Monitoring's are consistent with Evidence Action's finding in Kenya, where independent surveyors obtained chlorination rates representing 55\% of those calculated by Evidence Action.
\end{itemize}

Our analysis in Section \ref{sec:adoption-ea}, indicates that the factors that contribute the most to differences between estimates based on the Census and the Promoter Sample are unlikely to affect Evidence Action's estimate. Therefore, we would expect Q3 Adoption Monitoring results to be consistent with our main estimates. However,\textit{ given the differences observed and the fact that we can discard most other explanations, a combination of sampling variation, surveyor incentives, and potential deviations from survey protocols are left as the most plausible explanations for the differences observed.}

\subsection{Potential explanations for differences estimates obtained using the Census and the Adoption Monitoring methods}\label{sec:adoption-dil}

This Section discusses potential explanations for the differences in chlorine residual detection rates observed between our main estimates, from the Census Sample, shown in Table \ref{tab:headlines-vil}, and estimates that approximate Evidence Action's Adoption Monitoring protocols, from the Promoter Sample, shown in Table \ref{tab:headlines-am}.

Figure \ref{fig:adoption-comparison} compares the TCR detection rates across the different methods used. In Uganda, estimates from the Promoter Sample are 50\% \textit{higher} than those from the Census Sample. In Malawi, adoption estimates among households using water points with DSW are similar across the two samples, but ILC estimates from the Promoter Sample are 50\% \textit{lower} than those from the Census Sample. 

\subsubsection{Sample selection of water points}\label{sec:adoption-wpselection}

When designing survey protocols, we intended for estimates following both the census and the monitoring methods to be representative of all water points with in sampled villages. However, as discussed in Section \ref{sec:data}, the field team was unable to identify promoters for all water points found. This could lead to systematic difference between the water points used by households in the Census Sample and the Promoter Sample.

\textit{We find evidence of sample selection of water points into the Promoter Survey in Uganda}. The water points with DSW whose promoters were surveyed are more likely to have functional and filled dispensers, and water samples from these water points are more likely to have FCR detected after treating with chlorine from the dispenser. We find no relevant differences between water points in Malawi.

\textit{This is reflected in the resulting chlorination rates}: in Uganda, households using the water points with DSW covered by the Promoter Survey are around 90\% ($\approx$ 36.3\%/23.9\%) more likely to have TCR detected in their water samples (Table \ref{tab:adoption-wp}). In Malawi, there is no statistically significant difference among households using water points with DSW. However, households using water points with ILC covered by the Promoter Survey are roughly 50\% ($\approx$ 33.8\%/18.1\%) more likely to have TCR detected. 

\textit{However, sample selection of water points can only explain a small portion of the differences between our main estimates and those obtained when approximating Adoption Monitoring methods.} There are fewer households using water points excluded than included in the promoter survey in the Census Sample, so although sample selection is present, the difference in chlorine detected rates between all households in the Census Sample and those using water points covered by the Promoter Survey is not statistically significant.\footnote{Figure \ref{fig:adoption-selection}, column 1 vs column 2.}

\subsubsection{Sample selection of households}\label{sec:adoption-hhselection}

The list of households using water points provided by promoters is another potential source of difference. Promoters’ more limited knowledge would introduce noise into the data. For example, in some cases promoters relied on lists of water point users recorded in previous years, dating back as far as dispenser installation. Several additional factors could bias estimates in different directions:

\begin{itemize}
    \item If a household uses more than one water point, promoters may not know whether a water point is the household’s primary drinking water source, and including households whose primary source lacks does not have DSW/ILC would bias estimates downward;
    \item If promoters wish to demonstrate that a water point is widely used and should continue being treated, the list could include households whose primary source lacks DSW;
    \item If promoters remember mostly people with whom they have closer relationships or to whom they recently discussed chlorination, the list could lead to overestimation of chlorination rates;
    \item If promoters expect surveyors to speak with listed households and wish to demonstrate good performance, the list will more likely include households known to use chlorine, biasing estimates upward;
    \item Promoters would be expected to list all households using the water point regardless of location, while the household survey limits its sample to households within or up to 200m outside village boundaries.
\end{itemize}

\textit{The data shows that promoters are relatively effective at identifying households using water points with dispensers}. Among the households in the Household Census matched to the list of users provided by promoters, between 73\% and 93\% confirmed to use water points with DSW/ILC as their primary source of drinking water.\footnote{Table \ref{tab:adoption-matched}.}


\textit{However, we also find evidence indicating that promoters are less effective at identifying \textbf{all} of the users, leaving part of the households reached out of their lists.} Among the households in the Household Census whose primary source of drinking water had DSW/ILC and was covered by the Promoter Survey, around 70\% are included in the promoter list in Malawi, while in Uganda this share is only 45\%.\footnote{Table \ref{tab:adoption-hhs}.} Therefore, there could be sample selection with regard to which households are included in the promoter lists.

\textit{Promoter lists also include households that use water points with DSW/ILC, but not as their primary source of drinking water.} Among households who had their drinking water tested as part of the Promoter Sample, 85\% of those listed as using water points with DSW confirmed using them as their primary water sources.

\textit{In the Census Sample, TCR detection rates among households matched to the promoter list and not statistically different from those that weren't.} Since different combinations of the factors listed above could bias estimates in either direction, this is the best estimate of the overall impact of household selection bias on adoption estimates. 

\textit{These findings, combined with the lack of statistical significance in the TCR detection rates across the subsamples considered in Figure \ref{fig:adoption-comparison}, point to sample selection not playing a considerable role in the difference across estimates observedin Uganda.} Comparing columns 3 and 4 for Uganda in this figure further illustrates that sampling variation alone can lead to estimates similar to those observed in the Promoter Sample.

In Malawi, roughly 80\% of the households listed by promoters as using ILC matched to households in our data confirmed that their primary water point is an ILC water collection point.\footnote{Table \ref{tab:adoption-matched}} Among the households in the Census Sample that self-report using water points with ILC, those excluded from the promoter list are 85\% ($\approx$ 51.5\% / 28.3\%) more likely to have TCR detected in their water sample.\footnote{Table \ref{tab:adoption-hhselection}}. \textit{Therefore, in Malawi, household selection is a much more relevant source of differences than in Uganda.}

\subsubsection{Priming}

\textit{As discussed in Section \ref{sec:adoption-priming}, the duration of activities in the village could lead to an overestimation or adoption, as the time elapsed between the start of survey activities and the measurement of Chlorine Residual is long enough for the behavior of promoters and water point users to change from business as usual.} Because surveying Promoter Sample was the last activity carried out in each village, taking place after the Promoter Survey, the potential for bias is exacerbated in these estimates compared to the Census Sample.

\textit{The data indicates that priming affect adoption estimates in Uganda}, where TCR detection rates are 30\% ($\approx$ 37\%/28.1\%) higher among households tested in the second or third day of Household Survey activities compared to households surveyed in the first day.\footnote{Table \ref{tab:adoption-day}.}\footnote{The ideal test to determine how households react to the presence of the survey team would compare Chlorine Residual detection rates in households surveyed as part of both the Census and the Promoter samples and determine whether they were higher in the second test. However, too few households in our data were tested twice.} The difference between the days is not significant in Malawi.

The Uganda field team reported a case where, following the water point census, the promoter visited households in the village and reminded them to treat their water with chlorine. After this, we included two questions in the survey: one asking whether the household had discussed water treatment with the promoter in the week before the survey, and one asking if they had been told by anyone in the village about the surveys that were taking place. Because these questions were only included when the data collection was almost complete, estimates are very noisy. We observe the following stylized facts:
\begin{itemize}
    \item Households who had discussed the data collection with someone in the village were more likely to test positive for TCR both in the Census\footnote{Figure \ref{fig:adoption-promoter}, columns 1 and 2.} and the Promoter Sample\footnote{Figure \ref{fig:adoption-promotermon}, columns 1 and 2.};
    \item Households who had discussed the water treatment with the promoter in the week leading up to the survey where more likely to have TCR detected than households that had discussed the surveys with someone else as well as houseohlds who showed no indication of priming;\footnote{Figures \ref{fig:adoption-promoter} and \ref{fig:adoption-promotermon}, columns 2 and 3.}
    \item Households in Uganda were more likely than households in Malawi to have discussed the survey with someone else in the village and to have discussed water treatment with the promoter in the week before they were surveyed;\footnote{Table \ref{tab:adoption-priming}.}
    \item Households in the promoter list were more likely to have discussed the survey and to have engaged with the promoter in the week before the survey than other households in the Census Sample, and households in the Promoter Sample are more likely to have done both than households in the Census Sample;\footnote{Table \ref{tab:adoption-priming}.}.
\end{itemize}

\textit{As a result, we believe priming to be the most likely explanation for the higher chlorination rates observed in the Promoter Sample estimates in Uganda.} 


\textit{The extended presence of IPA field teams may bias chlorine adoption estimates in both the Household and Monitoring Surveys upward}, as promoters have opportunities to refill dispensers and remind households to add chlorine to their drinking water and the village population becomes more aware of water treatment practices. 

\subsubsection{Households living outside of village boundaries}

As discussed in \ref{tab:diff-reach-outside}, while the Household Census restricts listed households to those living within 200 meters from the village boundaries, the Promoter Survey included anyone using the water points, regardless of their location. 

\textit{The inclusion of more households living outside of the village boundaries does not explain the higher adoption estimates in the Promoter Sample.} In the Census Sample, TCR detection rates are lower among households living outside of village boundaries, which means that including more of these households would lead to lower estimates. However, the share of households living outside of village boundaries is comparable in the Census and the Promoter Samples. Finally, restricting the Census Sample to households living inside of village boundaries does not significantly increase adoption estimates, and the difference between the two samples is still statistically significant even if we exclude such households from both of them.

\subsection{Potential explanations for differences between this report's and Evidence Action's estimates}\label{sec:adoption-ea} 

\subsubsection{Sample selection of households}

Prior to data collection, our main hypothesis to explain the difference between estimates obtained by Evidence Action Adoption Monitoring and other available estimates was sample selection of households into the promoter list. However, as discussed in Section \ref{sec:adoption-hhselection} we find little evidence in our survey to support this explanation. Therefore, other factors must have a higher impact.

\subsubsection{Sample selection of water points}

In our survey, it was possible that water points covered by the Census Sample and the Promoter Sample were not comparable due to the exclusion of water points whose promoter could not be surveyed from the latter. Section \ref{sec:adoption-wpselection} explains that althought we find evidence of sample selection in Uganda, the number of excluded water points is small enough that this does not lead to significant differences in adoption estimates.

Sample selection of water points is even less likely to explain difference between our main estimates and Evidence Action's Adoption Monitoring estimates. Additionally, we would expect any bias on Evidence Action's estimates to lead to \textit{lower} adoption estimates. This is because:

\begin{itemize}
    \item Evidence Action’s protocol would still include the water points excluded from our Promoter Sample, by obtaining a list of water point users from a knowledgeable person other than the promoter.
    \item Our promoter-focused approach would be expected to introduce upward bias into estimates following, as promoters are better positioned than typical village members to identify both households using the water points and households that chlorinate their water, and may be more motivated to prioritize successfully adopting households when selecting survey respondents. 
    \item The promoters who can be more easily identified, and therefore surveyed by our Promoter Survey, are also more likely to be in touch with Evidence Action and, presumably, to be conducting promotion activities in the village, which should lead to higher chlorine adoption rates.
\end{itemize}

Given that our main estimates are lower than Evidence Action’s Q3 Monitoring estimates, and that sample selection of water points plays a small part in the differences between our main estimate and those based on the Promoter Sample, it is unlikely to explain the differences.

\subsubsection{Survey timing and priming}\label{sec:adoption-priming}

Although priming is the most likely explanation for differences between our main estimates and those that use a more similar method to Evidence Action's, it is unlikely that it would explain the difference between our estiamtes and Q3 Adoption Monitoring. Both ours and Evidence Action's protocols stipulate that promoters should only be contacted when the surveyor is ready to conduct the interview. However, the survey activities differed substantially in duration: Evidence Action monitoring staff spent only one day in each village, while IPA teams remained for an average of five days, conducting Monitoring Surveys on the final day. Therefore, if anything, priming should \textit{decrease} the difference between Evidence Action's estimates and ours, and it does not help us explain the observed results.

\subsubsection{Surveyor's independence}

A key methodological difference between DIL and Evidence Action protocols is who collects the data. Our estimates rely on data collected by independent enumerators hired by IPA, while Evidence Action uses their own local staff. This means surveyors and promoters may respond to different incentives:

\begin{itemize}
    \item Evidence Action surveyors may have existing relationships with promoters or implementation teams, creating incentives to portray them positively;
    \item Promoters were chosen by their communities to be the point of contact with Evidence Action and may seek to maintain positive relationships with the organization;
    \item Evidence Action staff may have interests in program continuation, which depends on positive results.
\end{itemize}

All these factors create potential incentives for surveyors and promoters to seek outcomes favorable to program success, which we would expect to bias Evidence Action estimates upward relative to those obtained via independent surveys.

Although we lack the data to test the impact of this factor on estimates, empirical evidence from Kenya supports the hypothesis that it does play a role. When Evidence Action examined identical households using both measurement approaches, the independent household survey found that 21\% of households tested positive for chlorine residual, while the Evidence Action Monitoring Survey reported 38\%. This means the independent survey estimate represented only 55\% of the Evidence Action figure.

Our results are consistent with the findings from Kenya. In Malawi, the independent household survey estimate (26\%) represents 51\% of the Evidence Action monitoring figure (51\%). Similarly, in Uganda, the independent estimate (30\%) represents 58\% of the Evidence Action monitoring result (52\%).\footnote{Table \ref{tab:compare-adoption}.}

Given that other factors cannot account for the differences observed and that this is the only one that is consistent with any findings in the data, it remains the most plausible explanation.


\subsubsection{Other possible causes of divergence}

The following factors may also contribute to the differences, but we are unable to test them adequately:

\begin{itemize}
    \item \textbf{Water point sampling variation:} IPA and Evidence Action did not sample the same water points, and sampling variation may explain part of the difference.
    \item \textbf{Time since training of surveyors:} IPA surveyors were trained between one week and four months before interviews took place, but the timing of Evidence Action staff retraining is unknown. This would introduce noise into measurements, but the direction of any bias is unclear, as more experience may lead surveyors to develop better skills and judgement or to forget protocols and develop bad practices.
    \item \textbf{State of equipment:} The equipment used in our data collection was procured specifically for this exercise, and all reagents were new. We lack data about how long Evidence Action’s equipment has been in use or when reagents were procured. The use of old materials could bias estimates in either direction -- for example, discolored color wheels would bias estimates upward, while degraded DPD reagents would bias estimates downward.
    \item \textbf{Deviations from randomization protocol:} Household randomization into our Household Survey was recorded in the data, allowing us to observe whether sampled households were replaced. In Evidence Action’s protocol, this is recorded on paper, leaving more room for enumerators to choose whom they survey (e.g., households closer to the promoter’s house or households indicated by the promoter).

\end{itemize}